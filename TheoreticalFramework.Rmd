---
title: "Open vs. closed innovation: Using online network data to measure innovation"
author: "Benjamin Snow and Oliver Bott"
date: "24 October 2014"
output:
  html_document:
    fig_caption: yes
    number_sections: no
  pdf_document:
    fig_caption: yes
    number_sections: yes
bibliography:
    - Packages.bib
    - Main.bib
---

============

```{r include=FALSE}
# Set working directory. Change as needed
setwd('C:/Users/a6p/Desktop/Uni 2014/E1161 - Collaborative Research/Final Project/')
```

```{r include=FALSE}
# Install packages to pull OECD data

# install.packages("devtools")
require("devtools")
library("rsdmx")
```


## Introduction

Policy makers worldwide have a profound interest in innovation for its significance for the creation of wealth and economic security. @taylor2004 views innovation as "the driving force behind modern economic growth, relative industrial power, and competitive advantage" (p.222). @schumpeter1942 greatly shaped the innovation discourse with the concept of structural change and the business cycle, the process he termed "creative destruction". Numerous studies, for example the Innovation Union Scoreboard[^IUS] and the OECD Science, Technology and Innovation Scoreboard[^STI], have attempted to measure and compare the innovation performance on the national level.  However, most examinations of innovation have usilized national level patent data, relying on this form of registering of proprietary data as a means of measuring innovation.  This leaves largely unexplored other, more open measures of innovation. The relatively recent emergence of network-based research systems offer new and potentially more instructive metrics by which to measure innovation, compared to protected closed knowledge. 

This research project examines the potential preferability of using collaborative online network data on the city-level as an innovation indicator. By doing so, this work will critically assess current innovation indicators in the hope of offering new alternatives for measuring and understanding innovation. Since @freeman2009, among other scholars, called for the continuous improvement of innovation measurement, this work seeks to go beyond the widespread use of patent data to contribute to the refinement of innovation indicators, and the field as a whole.

## State of the Field

**Defining Innovation**

Using a rather grand view in his understanding of innovation, @schumpeter1942 sees innovation as "a process of industrial mutation, that incessantly revolutionizes the economic structure from within, incessantly destroying the old one, incessantly creating a new one". In a more understated characterization, @smith2005 defines innovation as "the creation of something qualitatively new, via processes of learning and knowledge building. It involves changing competences and capabilities, and producing qualitatively new performance outcomes" [@smith2005, 149]. While it is widely accepted that innovation can take many forms, e.g. product, process, marketing and proccess innovations, @frankelius2009, in his extensive literature review of innovation studies, criticizes the widespread underlying assumption that innovation is limited to technological innovation. While accepting @frankelius2009's critique of innovation as taking place outside of the technological realm, for the purpose of this study technological innovation, and specifically software innovation, will be the primary focus following relatively closely to @smith2005's definition.

**Measuring Innovation**

The frequent technological focus when measuring innovation can partly be explained by the difficulties associated with innovation's measurement. @smith2005 notes the measuring challenge, as innovation is by definition a novelty and thus commensurability is a demanding task. For these reasons innovation has traditionally though controversially been measured by looking either at its inputs, outputs, our throughputs. Attempting to measure patents by inputs often focuses on resources ,such as personnel and equipment allocated to R&D, which @freeman2009 notes is often overestimating innovation in R&D by including the routine with the novel. @freeman2009 compares this with output oriented measures, which are often based on what be concludes are the already inadequate measures such as GDP. Other output oriented attempts include other economic outputs in the form of patents, product output and related revenues [@freeman2009]. 

In his 2004 study of the impact of the Varieties of Capitalism (VoC) policy on innovation, @taylor2004 explores the concept of 'waves of innovation' wherein radical product innovations converge on a dominant product design, afterwhich a flurry of process innovations in manufacturing take place in attempts to lower the cost. Citing the example of the automobile industry, which for 30 years had a high varience in features and operability, afterwhich a dominant product gave way to continued innovations in design and manufacturing. @taylor2004 attempts to show these waves of innovation. He uses patent data taken from 1963 to 1999 in six different industries and their future citation levels and uses an Ordinary Least Squares (OLS) model to test what he terms the 'industry-innovation assumption'. @smith2005 mentions the development of new indicators, but focuses on country level economic measures, which are helpful for comparability.

An indicator most often found in innovation research is patent data [see @taylor2004]. A patent is a "temporary legal monopoly granted by the government to an inventor for the commerical use of his or her invention [@taylor2004, 229). A patent constitutes a property right awarded when an invention is shown to be non-trivial, useful, and novel [@taylor2004, 230]. Patents were first used to measure demand-side determinants of innovation by Scherer and Schmookler [REFERENCE], and have been used in the analysis of innovation activity for over three decades [@taylor2004, 230). While long hindered by technological limitations requiring labor intensive patent analysis, recent improvements due to machine-readable patent data have spurred recent econometric analysis, as did for example @hall2005 who analyzed millions of patents.

**Limitations of Patent Data**

Despite the usefulness of patent data, @taylor2004 found several limitations to using patents to measure innovation. First, patents suffer from a 'classification problem' as assigning specific industries to patents, as industry of innovation and industry of production can change over time. Additionally, patents may vary widely in significance, both technically and economically [@taylor2004, 231]. Most significantly for the purpose on this study, @taylor2004 as well as @pakes1980 found that “patents are a flawed measure particularly since not all new innovations are patented and since patents differ greatly in their economic impact” (p.378). Thus, while for some considerable time patents have been considered to be the most effective proxy with which to measure innovation, even recent studies have begun to examine alternatives due to patents limitations in measuring innovation. This is why for example @taylor2004 also used publication data as an innovation proxy.

Both data on patents and academic publishing include only proprietary or closed forms of innovation, in the same manner that @taylor2004 finds that 'not all inventions are patentable', not all innovation needs to be an invention.  Taylor notes this point implicitly in searching for a way to weight the size of innovation from one published paper to the next. @taylor2004 uses paper citations as a measure to weight the size of an innovation. 

Despite these efforts, current developments in research indicate that „characteristics that were important last century may well no longer be so relevant today and indeed may even be positively misleading“ [@freeman2009, 3]. Today we witness a shift away from the belief that innovation only occurs in professional R&D labs, a change towards what @freeman2009 calls "research without frontiers" (p.13). Even though networks and research collaborations become increasingly important, there have been relatively few studies focusing on network data [see for example @breschi2005]. Even where research networks have been analysed, the focus is too often on economically useful knowledge [see @acs2002]. Other studies focusing on research networks focus on other protected collaborative networks [see @ponds2010].

**Using Network Data as Innovation Indicator**

Since @freeman2009 among others called for the continuous improvement of innovation measurement, this work seeks to contribute to the refinement of innovation indicators. The purpose of this study is to explore the conceptual and statistical viability of a new metric by which we can measure innovation. New metrics are needed, because "too much energy has gone into squeezing the last bit of juice out of old data collected for different purposes relative to the design of new types of data" (Kenneth Arrow, quoted from Smith 2005, p. 148).

**Research Question**

In the light of the above mentioned state of innovation research we want to examine the following the following research question: 
**To what extent can open innovation network data add to the measurement of innovation performance?**

# Methodology

For examining open network data against patent data, this study will rely on two data sets. One is the API data for open networks. Similar to other network studies we will be using the association of a contributor, but rather based around their reputation, and not their works citation level (**we have not written anything in the methods on API yet**).

For closed innovation we use patent at the city level, taken from the Organization for Economic Co-operation and Development[^OECD]. Patent data was taken for a preliminary sample of 20 cities overall, ranging from six different countries, including their country level patent data, for general comparison over the time period 2000 until 2012.  From the same database, we also use GDP per capita data and environmental data, as other variables which could prove significant in explaining differences in innovation.

This OECD data's format is in ( ).  To clean this data for effective statistical comparison, the deletion of several empty rows, and the renaming of relevant variables with their city name rather than an attributed code, for clarity.  Past this, all datasets must be effectively merged.

To examine open data innovation, data was obtained from the Application Programming Interface (commonly known as an API) of the git repository web-based hosting service Github[^GIT]. Github's use of distributed revision control and source code management make it a commonly used software development collaboration tool. The ability to see 

We obtain the patent data on the city level from the OECD database. The R [@CiteR] package [@RSDMX] necessary for obtaining the OECD dataset (see above).

In the next step we pull the OECD data from the online database using [@RSDMX]. As we are interested in patent data, we work with data indicating the PCT patent applications per 10,000 inhabitants. As control variables we also use GDP per capita and green space available per inhabitant in square meters per inhabitant (see above).

```{r include=FALSE}
# Pull OECD city patent data
dataURL <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/DEU+DE001+DE002+DE003+DE007+DE035+DE507+ESP+ES001+ES002+FRA+FR001+ITA+IT001+IT002+IT009+SWE+SE001+SE002+SE003+USA+US014+US048+US084+US146+US234.PCT_INTENSITY?startTime=2000&endTime=2012"

sdmx <- readSDMX(dataURL)
city_pat <- as.data.frame(sdmx)

# Pull OECD GDP per capita data

dataURL2 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/DEU+DE001+DE002+DE003+DE007+DE035+DE507+ESP+ES001+ES002+FRA+FR001+ITA+IT001+IT002+IT009+SWE+SE001+SE002+SE003+USA+US014+US048+US084+US146+US234.GDP_PC?startTime=2000&endTime=2012"

sdmx <- readSDMX(dataURL2)
city_gdp <- as.data.frame(sdmx)

# Pull OECD environmental data

dataURL3 <- "http://stats.oecd.org/restsdmx/sdmx.ashx/GetData/CITIES/DEU+DE001+DE002+DE003+DE007+DE035+DE507+ESP+ES001+ES002+FRA+FR001+ITA+IT001+IT002+IT009+SWE+SE001+SE002+SE003+USA+US014+US048+US084+US146+US234.GREEN_AREA_PC?startTime=2000&endTime=2008"

sdmx <- readSDMX(dataURL3)
city_env <- as.data.frame(sdmx)
```


In the next step basic cleaning of the data is undertaken.

```{r echo=TRUE}
# Clean table by deleting and renaming rows
city_pat$VAR <- NULL # Delete columns
city_pat$attrs.df <- NULL

colnames(city_pat) <- c("METRO_ID" , "Year" , "Patent_Intensity") # Rename columns

# Clean table by deleting and renaming rows
city_gdp$VAR <- NULL # Delete columns
city_gdp$attrs.df <- NULL

colnames(city_gdp) <- c("METRO_ID" , "Year" , "GDP") # Rename columns

sdmx <- readSDMX(dataURL3)
city_env <- as.data.frame(sdmx)

# Clean table by deleting and renaming rows
city_env$VAR <- NULL # Delete columns
city_env$attrs.df <- NULL

colnames(city_env) <- c("METRO_ID" , "Year" , "GreenArea") # Rename columns

```

After cleaning the data frames and sorting the data, we merge the three data sets into one using the following code: 


```{r echo=TRUE}
# Merge all 3 OECD citydata sets

oecd_pat_gdp <- merge(city_pat , city_gdp , by=c("METRO_ID" , "Year"))
oecd <- merge(oecd_pat_gdp , city_env , by=c("METRO_ID" , "Year"))
```

```{r include=FALSE}
# Turn Year into numeric
sapply(oecd, mode)
transform(oecd, Year = as.numeric(Year))
```

To further clean up the table we rename the city and country IDs.

```{r echo=FALSE}
# Example code to further clean table
oecd$METRO_ID <- replace(oecd$METRO_ID , oecd$METRO_ID == "DEU" , "Germany")
```

# Descriptive statistics

The characteristics of the city data obtained through the OECD database are shown in this section. The summary statistics give some first impression of the OECD city data set.


```{r echo=FALSE}
# Summary statistics for the three variables
summary(oecd$Patent_Intensity ,  digits = 3)
summary(oecd$GDP ,  digits = 3)
summary(oecd$GreenArea ,  digits = 3) 
```

In the data set, the mean for PCT patent application per 10,000 inhabitants is 3.44. The histogram indicates that the mean is not very meaningful. There are many cities with patent applications much lower and some cities with around 5.5 patent applications. This finding supports our claim that on the regional level there are great variations in patent activity, which undermines national level analyses.

```{r, echo=FALSE}
hist(oecd$Patent_Intensity,
      main = 'PCT applications',
      xlab = 'PCT patent applications per 10,000 inhabitants')
```

The histogram indicates the relationship between GDP and patent intensity. 

```{r, echo=FALSE}
plot(oecd$Patent_Intensity , oecd$GDP, 
      main = 'Patent intensity and GDP per capita',
      xlab = 'PCT patent applications per 10,000 inhabitants',
      ylab = 'GDP per capita')
```

**Statistical Model**

On the type of analysis and question, this study will use an ordinary least squares (OLS) model to examine the relationship between patent and open data. If their is a relationship this would presumably show that open data shows the same innovation patent data show, but shows the 'throughput' of innovation rather than the 'output'. Open data having a relationship to patent data would presumably show innovation as a throughput, since it is measured by people finding those contributing in open data as innovators (followers on github), rather than looking at the specific innovation at completion (patents).  


**Preliminary Statistics**

> Early statistical analysis findings and expected types of statistical analysis based upon nature of datasets used


[^IUS]: For the latest edition see [http://ec.europa.eu/enterprise/policies/innovation/policy/innovation-scoreboard/index_en.htm].
[^STI]: For the latest edition see [http://www.oecd.org/sti/scoreboard.htm].
[^OECD]: Online accessible on [http://stats.oecd.org].
[^GIT]: Online accessilbe on [https://github.com/].
